---
header-includes:
   \usepackage{amsmath}
   \usepackage{geometry}
   \usepackage{pdfpages}
   \usepackage{fontspec}
   \usepackage{pdfpages}
   \usepackage{graphicx}
   \usepackage{amsmath}
   \usepackage{atbegshi}
   \usepackage{fancyhdr}
   \usepackage{tocloft}
   \usepackage{tcolorbox}
   \usepackage{xcolor}
   \definecolor{bleu}{RGB}{0,0,255}
   \usepackage{everypage}
   \usepackage{everypage}
   \usepackage{graphicx}
   \usepackage{fancyhdr}
   \pagestyle{fancy} 
   \definecolor{mybrown}{RGB}{139,69,19}
   \fancyhead[R]{}
output: 
  pdf_document: 
    number_sections: true
    latex_engine: xelatex
    fig_height: 4
    fig_width: 5
    fig_caption: true
    keep_tex: true
lang: fr
bibliography: references.bib
urlcolor: blue
editor_options:
  chunk_output_type: console
  markdown: 
    wrap: 72
---

\setcounter{tocdepth}{5}                
\renewcommand\contentsname{\begin{center}\textcolor{brown}{Sommaire}\end{center}}
\AtBeginShipout{
  \ifnum\value{page}=1\thispagestyle{empty}\fi}
\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}
\fancyhead[L]{Elèves Ingénieurs}
\fancyhead[R]{\textcolor{brown}{@Alex, Ali, Richard \& Toussaint}}
\fancyfoot[C]{\thepage}
\fancyfoot[L]{Mars 2025}
\fancyfoot[R]{Projet Statistique}
\AddEverypageHook{
  \ifnum\value{page}>1 
    \fancyhead[L]{Elèves Ingénieurs}
    \fancyhead[R]{\textcolor{brown}{@Alex, Ali, Richard \& Toussaint}}
    \fancyfoot[C]{\thepage}
    \fancyfoot[L]{Mars 2025}
    \fancyfoot[R]{Projet Statistique}
  \else
    \fancyhead[L]{} 
    \fancyhead[R]{}
    \fancyfoot[C]{}
    \fancyfoot[R]{}
  \fi
}
```{=latex}
\tableofcontents
```

\newpage

\renewcommand\listtablename{\begin{center}\textcolor{brown}{Liste des Tableaux}\end{center}}
\renewcommand\listfigurename{\begin{center}\textcolor{brown}{Liste des Figures}\end{center}} 

\setlength{\cftfignumwidth}{3em}
\setlength{\cfttabnumwidth}{3em}
```{=latex}
\listoftables
```

\newpage

```{=latex}
\listoffigures
```

\newpage

```{r setup, include=FALSE, fig.align='center'}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE
)
```

```{r}
# Chargement des packages
library(stringi)
library(dplyr)
library(knitr)
library(tidyverse)
library(summarytools)
library(gridExtra)
library(purrr)
library(skimr)
library(spdep)
library(geosphere)
```

```{r }
# Importation des données de démonstration

demo <- read.csv("../data/demof2.csv", sep = ";", dec=",")
#View(demo)
#str(demo)
names(demo)[names(demo) == "Libellé"] <- "libelle_maj"

## Fonction prenant en entrée un base et nettoie les noms des colonnes

nettoyer_noms_colonnes <- function(data){
  names(data) <- names(data) %>%
    stri_trans_general("Latin-ASCII") %>% # Suppression des accents
    gsub("\\s+", "_", .) %>% # Remplacement des espaces par des underscores
    gsub("\\.+", "_", .) %>% # Remplacement des points par des underscores
    tolower() # Conversion en minuscules
  return (data) 
}

## Nettoyage des colonnes de la base demo
demo <- nettoyer_noms_colonnes(demo)
#names(demo)


# Fusion des bases et création des varaiables

## Importation de la base generalise
generalise <- read.csv("../data/generalise.csv", sep=";")
#str(generalise)

## Importation de la base pour les lon et lat manquantes
donnees_manquantes <- read.csv(
  "../data/communes_manquantes_latitudes_longitudes.csv", sep=";", dec=".")
#str(donnees_manquantes)

donnees_manquantes$longitude <- donnees_manquantes$longitude %>%
  str_replace_all(",", "") %>%  # Supprime les virgules
  as.numeric()

## Nettoyage dans les noms des colonnes
generalise <- nettoyer_noms_colonnes(generalise)
donnees_manquantes <- nettoyer_noms_colonnes(donnees_manquantes)

## Fusion des bases
data <- demo %>% 
  inner_join(generalise, by ="code") %>%
  left_join(donnees_manquantes, by = "code") %>%
  mutate(
    longitude = ifelse(is.na(longitude.x), longitude.y, longitude.x),
    latitude = ifelse(is.na(latitude.x), latitude.y, latitude.x)
  ) %>%
  select(-longitude.x, -longitude.y, -latitude.x, -latitude.y)


#nrow(demo)
#nrow(generalise)
#nrow(data)

## Filtrons les communes n'appartenant pas au département 97
data <- data %>% filter(departement != 97)



## Création de la variable taux de visites
data <- data %>% 
  mutate(taux_visites = nb_visite/population_municipale_2021_x)

## Création de la variabe taux de visites pour les plus de 19 ans
data <- data %>%
  mutate(pop_19_ans_ou_plus = pop_15_ans_ou_plus - pop_15_19_ans,
       taux_visites_19_ans_ou_plus = nb_visite / pop_19_ans_ou_plus)

#summary(data$taux_visites)
#summary(data$taux_visites_19_ans_ou_plus)

#skim(data)




## Exportation de la base finale 
write.csv(data, "../data/data.csv", row.names = FALSE)

```

# \textcolor{brown} {Introduction}

La répartition géographique des besoins en soins de santé est un enjeu majeur pour les politiques publiques, notamment en ce qui concerne l'accès aux services de médecine de ville. Les inégalités territoriales dans l'offre et la demande de soins peuvent entraîner des disparités significatives en matière de santé, affectant particulièrement les populations vivant dans des zones sous-dotées en professionnels de santé. Comprendre ces dynamiques spatiales et socio-démographiques est essentiel pour identifier les zones prioritaires et orienter les décisions en matière d'allocation des ressources.

Dans ce contexte, ce travail propose une modélisation du nombre de consultations en médecine de ville à l'échelle communale, en tenant compte des caractéristiques démographiques, socio-économiques et spatiales des communes. L'objectif est double : d'une part, analyser les facteurs influençant la demande de soins, et d'autre part, identifier les zones susceptibles de dépasser un seuil critique de "désert médical". Pour ce faire, nous nous appuierons sur une base de données riche et variée, comprenant des informations issues du Système National des Données de Santé (SNDS) pour la période 2018-2022, ainsi que des indicateurs socio-démographiques et géographiques.

Notre approche méthodologique repose sur une combinaison de techniques statistiques et spatiales. Nous commencerons par une analyse descriptive et cartographique des données pour visualiser les tendances et les disparités territoriales. Ensuite, nous utiliserons des modèles de régression de Poisson pour modéliser le nombre de consultations annuelles, en tenant compte des effets fixes (caractéristiques des communes) et des effets aléatoires (variations spatiales). Enfin, une régression logistique binaire sera employée pour évaluer la probabilité qu'une commune dépasse un seuil prédéfini de "désert médical".

Ce travail s'inscrit dans une perspective à la fois académique et opérationnelle. Sur le plan académique, il contribue à l'étude des inégalités territoriales en santé en proposant une méthodologie robuste pour l'analyse spatiale des données de soins. Sur le plan opérationnel, il fournit des outils pour identifier les zones prioritaires et soutenir la prise de décision en matière de politiques de santé publique.


\newpage


# \textcolor{brown} {Présentation du contexte}

## Intérêt de l'étude

## Cadre conceptuel de l'étude

Dans cette partie, nous allons définir certainses notions clés qui apparaissent dans notre étude entre autres, le nombre de visites, le nombre de visites espérés ainsi que le taux de visite. 

1. Nombre de visites espérés

Le nombre de visite espérés, terme qui apparaitra dans notre modélisation est le nombre de visite qu'il y aurait eu dans chaque commune si le taux de visite était le même dans dans ces dernières. En d'autres terme si $r$ est le taux moyen de visite alors, le nombre de visite escompté noté $\mu$ est calculé par :

\begin{tcolorbox}[colback=mybrown!10!white, colframe=mybrown!80!black, boxrule=0.5mm]
$$ \mu_i = r * P_i$$
\end{tcolorbox}


où $P_i$ est le nombre d'habitants dans la commune $i$

2. Taux de visite

Le taux de visite n'est rien d'autre que le nombre moyen de visite dans chaque commune. IL est calculé en divisant le nombre de visite par la population de la commune en question. En d'autres termes, il s'agit du nombre de visites que chaque habitant de la commune a effectué en moyenne. 

\begin{tcolorbox}[colback=mybrown!10!white, colframe=mybrown!80!black, boxrule=0.5mm]
$$\tau_i = \frac{n_i}{P_i}$$
\end{tcolorbox}
où $\tau_i$ et $n_i$ sont respectivement le taux et le nombre de visite de la commune $i$. 



## Revue de littérature

La modélisation des visites dans les hôpitaux est cruciale pour
comprendre les dynamiques de la santé publique et pour optimiser la
gestion des ressources médicales. Dans ce contexte, les modèles de
régression de type Poisson généraux, en particulier les modèles mixtes
généralisés (GLMM), sont souvent utilisés pour gérer les données de
comptage, en tenant compte des spécificités démographiques et
géographiques des agglomérations, ici définies par les communes.

Les recherches antérieures, comme celles de Mohebbi et al. (2011),
montrent l'importance d'intégrer des effets spatiaux dans les modèles de
comptage, surtout lorsqu'on évalue des phénomènes tels que le cancer
œsophagien (EC) dans des provinces spécifiques. Leur étude souligne
comment la non-prise en compte de l'autocorrélation spatiale peut
conduire à une estimation biaisée des effets des variables
socio-économiques sur l'incidence des maladies. Ce phénomène pourrait
également s'appliquer à la modélisation des visites à l'hôpital, où
certains facteurs ouent un rôle significatif.

Selon l'article, trois structures d'autocorrélation peuvent être
appliquées dans le cadre de la régression Poisson lorsqu'on traite des
données de comptage. Ces modèles comprennent : 

1. **Modèle Poisson avec effets aléatoires non spatiaux** : Bien qu'utiles, ces modèles négligent
l'autocorrélation spatiale, ce qui peut conduire à une sous-estimation
des erreurs standard. 

2. **Modèle avec effets aléatoires spatiaux basés sur la distance** : Ce modèle prend en compte l'influence des
agglomérations voisines, mais peut ne pas capturer efficacement
l'hétérogénéité locale. 

3. **Modèle avec effets aléatoires de type voisinage** : Utilisant la structure conditionnelle autorégressive (CAR),
ce modèle est le plus adapté pour les données spatiales en intégrant les
interactions entre les communes. Pour notre étude, le modèle avec effets
aléatoires de type voisinage est recommandé pour la modélisation du
nombre de visites à l'hôpital en France, car il permet de mieux prendre
en compte l'effet de proximité entre communes.

L'application des principes issus de l'article de Mohebbi et al. peut
enrichir notre étude sur la fréquentation des hôpitaux en France. En
intégrant des effets aléatoires spatiaux adaptés à la structure des
données, nous pouvons réaliser des estimations plus précises et utiles
pour la planification hospitalière.

En ce qui concerne les facteurs explicatifs du nombre de visite dans les
hopitaux, plusieurs études se sont penchées sur ce sujet. De nombreuses
études ont montré que le nombre de consultations médicales est influencé
par divers facteurs sociodémographiques, allant des caractéristiques
individuelles aux contextes socio-économiques et territoriaux.

1.  Influence de l’âge et du sexe

L’âge constitue un déterminant majeur du recours aux soins. Les
personnes âgées, en particulier celles de 65 à 79 ans, consultent plus
fréquemment en raison de la prévalence accrue de maladies chroniques et
du suivi médical nécessaire à leur prise en charge [@statcan2022]. En revanche, la population jeune et en bonne santé présente
une utilisation plus sporadique des services médicaux. Le sexe est
également un facteur différenciant important. De manière générale, les
femmes consultent plus fréquemment que les hommes. Cette différence est
attribuée aux besoins spécifiques en santé reproductive, mais aussi à
une plus grande propension à rechercher des soins préventifs [@bag2024]. En revanche, les hommes,
notamment dans les catégories socio-professionnelles les plus actives,
ont tendance à sous-utiliser les services de soins, ce qui peut
entraîner des diagnostics plus tardifs et des complications médicales
accrues.

2.  Impact du statut socio-économique et du niveau d’éducation

Le revenu et la précarité économique influencent considérablement
l’accès aux soins. Les individus à revenu élevé bénéficient généralement
d’un meilleur accès aux consultations médicales, notamment grâce à une
plus grande couverture sociale et des assurances complémentaires leur
permettant de réduire les coûts associés aux soins [@bvs2023]. À l’inverse, les personnes en situation de précarité
rencontrent des obstacles financiers, administratifs et culturels qui
limitent leur recours aux soins, malgré des besoins souvent accrus en
raison de conditions de vie plus précaires. Le niveau d’éducation joue
un rôle clé dans la fréquentation des services de santé. Une instruction
plus élevée est associée à une meilleure connaissance des risques
sanitaires et à une adoption plus proactive des comportements de
prévention, ce qui entraîne un recours plus fréquent aux soins médicaux
[@bvs2023]. En revanche, un faible niveau d’éducation est
souvent corrélé à un moindre suivi médical et à une utilisation plus
tardive des services de soins, notamment en cas de complications.

3.  Influence du contexte familial et de l’environnement social

L’état matrimonial influence également la fréquence des consultations
médicales. Les personnes mariées ou vivant en couple consultent
davantage, bénéficiant du soutien d’un conjoint qui peut inciter à
prendre soin de sa santé et à consulter régulièrement un médecin
[@statcan2022]. Par ailleurs, l’accès à un médecin
traitant ou de famille constitue un déterminant important. Les patients
disposant d’un suivi médical régulier sont plus enclins à effectuer des
consultations préventives et à être orientés rapidement vers des
spécialistes si nécessaire [@statcan2022]. 

4. Perception de l’état de santé et accès géographique aux soins 

La perception de la santé est un facteur déterminant du recours aux soins.
Les individus qui considèrent leur état de santé comme excellent ou très
bon consultent rarement, tandis que ceux qui ont une perception négative
de leur état de santé ont tendance à multiplier les visites médicales
[@statcan2022]. Enfin, les inégalités spatiales dans
l’accès aux soins modulent également la fréquence des consultations. En
milieu urbain, la densité médicale plus élevée facilite l’accès aux
services de soins, tandis qu’en zones rurales ou médicalement
sous-dotées, les délais d’attente et les distances à parcourir
constituent des freins majeurs [@irdes2020].


\newpage



# \textcolor{brown} {Méthodologie}

## Présentation des données

Les données que nous avons utilisées nous proviennent de ...


## Motivation

Les modèles linéaires généralisés à effets mixtes (GLMM) combinent :

-   Les caractéristiques des modèles linéaires généralisés (GLM) pour
    modéliser des variables non-normalement distribuées.

-   Les propriétés des modèles à effets mixtes pour gérer des données
    groupées ou hiérarchiques.

## Modèles Linéaires Généralisés

Un GLM relie le prédicteur linéaire $\eta$ à la moyenne $\mu$ de la
réponse à travers une fonction de lien $g$ :\
$$ g(\mu) = \eta = \beta_0 + \sum_{i=1}^m \beta_i x_i $$\
Les distributions possibles incluent :

-   **Normale** : Régression linéaire classique, avec lien identité.

-   **Binomiale** : Régression logistique pour données binaires, avec
    lien logit.

-   **Poisson** : Régression de Poisson pour données de comptage, avec
    lien logarithmique.

### Régression Logistique

Modélise une réponse binaire ($y \sim B(n, p)$), où $p$ est la
probabilité de succès :\
$$ P(y | n, p) = \binom{n}{y} p^y (1-p)^{n-y} $$\
La probabilité $p$ est reliée au prédicteur par la fonction logistique
:\
$$ p = \frac{1}{1 + e^{-\eta}} \quad \text{où} \quad \eta = \beta_0 + \sum_{i=1}^m \beta_i x_i. $$\
Le log-vraisemblance est exprimé comme :\

\begin{tcolorbox}[colback=mybrown!10!white, colframe=mybrown!80!black, boxrule=0.5mm]
$$ \ell(\boldsymbol{\beta}) = \sum_{i=1}^n \left[ y_i \log{p_i} + (1-y_i) \log{(1-p_i)} \right]. $$
\end{tcolorbox}

### Régression de Poisson

Utilisée pour modéliser des données de comptage
($y \sim Pois(\lambda)$), où $\lambda$ est la moyenne et la variance :\
$$ P(y | \lambda) = \frac{\lambda^y}{y!} e^{-\lambda} $$\
Le lien logarithmique assure $\lambda > 0$ :\
$$ \log{\lambda} = \beta_0 + \sum_{i=1}^m \beta_i x_i $$\
L'espérance est $E[y] = \lambda$.

## Modèles Linéaires Mixtes

Ces modèles ajoutent des termes d'effets aléatoires
$\mathbf{Z} \mathbf{u}$ au prédicteur linéaire :\
$$ \mathbf{y} = \mathbf{X} \boldsymbol{\beta} + \mathbf{Z} \mathbf{u} + \boldsymbol{\varepsilon}, $$\
avec :

-   $\mathbf{u} \sim N(\mathbf{0}, \mathbf{G})$, les effets aléatoires.

-   $\boldsymbol{\varepsilon} \sim N(\mathbf{0}, \mathbf{R})$, les
    résidus.

La matrice de covariance totale est :\
$$ \mathrm{Var}(\mathbf{y}) = \mathbf{Z} \mathbf{G} \mathbf{Z}^T + \mathbf{R}. $$\
Les paramètres sont estimés par maximum de vraisemblance (ML) ou par
vraisemblance restreinte (REML).

## Modèles Linéaires Généralisés à Effets Mixtes (GLMM)

Un GLMM étend les GLM en intégrant des effets aléatoires :\
$$ g(\mu) = \mathbf{X} \boldsymbol{\beta} + \mathbf{Z} \mathbf{u}, $$\
où :\
- $g(\cdot)$ est la fonction de lien.\
- $\mathbf{u} \sim N(\mathbf{0}, \mathbf{G})$ est le vecteur d'effets
aléatoires.

Les paramètres sont estimés via des méthodes comme :\
- Approximations Laplaciennes.\
- Quadrature gaussienne adaptative.\
- Méthodes MCMC (chaînes de Markov Monte Carlo).

## Prédictions et Simulations

Les GLMM permettent deux types de prédictions :\
- **Conditionnelles** : Basées sur les effets aléatoires spécifiques
($\mathbf{u}$).\
- **Marginales** : En intégrant sur les effets aléatoires.

Les simulations utilisent des approches paramétriques pour évaluer la
variabilité et tester les hypothèses. Une approche courante est le
bootstrap paramétrique :\
1. Générer des données simulées basées sur les paramètres estimés.\
2. Réajuster le modèle pour chaque jeu de données simulé.\
3. Analyser la distribution des estimations obtenues.

# \textcolor{brown} {Analyse des résultats}

## Analyse descriptive

1. Description de la population d'étude 


Notre population d'étude est une population assez homogène en matière d'âge. Cependant plus on dépasse les 75 ans et moins on rencontre de personnes. D'autres part notre popuplation est fortement masculine avec une forte proportion des hommes quelle que soit la tranche d'âge à l'exception des tranches du troisième âge. 
```{r , fig.align='center', fig.cap= "Pyramide des âges"}
library(ggplot2)
library(dplyr)
library(tidyr)
df = data
colnames(df) <- gsub("homme_", "hommes_", colnames(df))
colnames(df) <- gsub("hommes_70_47$", "hommes_70_74", colnames(df))



# Sélectionner les colonnes de la pyramide des âges
age_groups <- c("0_4", "5_9", "10_14", "15_19", "20_24", "25_29", "30_34", "35_39",
                "40_44", "45_49", "50_54", "55_59", "60_64", "65_69", "70_74",
                "75_79", "80_84", "85_89", "90_94", "95_plus")

# Restructurer les données pour la visualisation
hommes_vars <- intersect(colnames(df), paste0("hommes_", age_groups))
femmes_vars <- intersect(colnames(df), paste0("femmes_", age_groups))

# Créer la pyramide des âges avec les hommes d'abord, puis les femmes
pyramide <- data.frame(
  Age = rep(age_groups, 2),  # Liste tous les âges d'abord pour les hommes, puis pour les femmes
  Sexe = c(rep("Homme", length(age_groups)), rep("Femme", length(age_groups))),
  Population = c(colSums(df[paste0("hommes_", age_groups)], na.rm=TRUE),
                 -colSums(df[paste0("femmes_", age_groups)], na.rm=TRUE))  # Femmes en négatif
)



ggplot(pyramide, aes(x=Age, y=Population, fill=Sexe)) +
  geom_bar(stat="identity", width=0.8) +
  coord_flip() +  # Pour afficher en pyramide
  scale_y_continuous(labels = abs) +  # Afficher les valeurs absolues
  labs(
       x="Tranche d'âge",
       y="Population",
       fill="Sexe") +
  theme_minimal() +
  scale_fill_manual(values=c("blue", "pink"))  # Couleurs pour Homme/Femme


```


Dans cette partie, nous allons réaliser quelques statistiques
descriptives sur nos données.

### Analyse univariée

```{r }
## Statistiques descriptives sur le nombre de visite

#summary(data$nb_visite)

```

1. Taux et Nombre de visites

L'analyse des statistiques descriptives sur le nombre de consultations
annuelles de médecin généraliste entre 2018 et 2022 révèle une
distribution fortement asymétrique à droite, avec une grande dispersion
des données. La moyenne de 19130 consultations, nettement supérieure à
la médiane de 9127, indique la présence de valeurs extrêmes tirant la
distribution vers le haut. Cette asymétrie est confirmée par l'écart
considérable entre le minimum de 1037 et le maximum de 765833
consultations par an.

La moitié des médecins généralistes effectuent entre 5993 et 17290
consultations annuellement, ce qui suggère une variabilité importante
dans la charge de travail. La médiane de 9127 consultations par an,
équivalant à environ 25 consultations par jour ouvrable, semble plus
représentative de l'activité typique d'un médecin généraliste que la
moyenne influencée par les valeurs extrêmes. Ces statistiques mettent en
lumière la diversité des pratiques et des charges de travail parmi les
médecins généralistes, avec potentiellement quelques cas atypiques
présentant un volume de consultations exceptionnellement élevé.

Le nombre de visites pouvant potentiellement être influencé par la
taille de la commune et donc par sa population, nous avons éliminer cet
effet en calculant le taux de consultations qui n'est autre que le
nombre de consultations moyennes par personnes.

2. Taux de mortalité et de Natalité

Dans les commmunes étudiées, le taux de natalité et de mortalité sont un peu élevées avec la plupart des taux variant entre 5 et 15 pour 1000 en ce qui concerne la natalité et 0 et 20 pour 1000 pour la mortalité. On remarque une corrélation négative entre ces deux taux. Néanmoins cette corrélation n'a à priori aucun sens. Par ailleurs, l'observation des distribution permet de constater que la natalité est nde façon générale élevée par rapport à la mortalité dans les communes étudiées. 
```{r fig.align='center', fig.cap= "Taux de Natalité et Taux de Mortalité"}
# 📌 Vérification et conversion des variables avant de tracer
# Vérification et conversion du taux de mortalité
if (class(df$taux_de_mortalite_annuel_moyen_2015_2021) != "numeric") {
  df$taux_de_mortalite_annuel_moyen_2015_2021 <- as.numeric(as.character(df$taux_de_mortalite_annuel_moyen_2015_2021))
}

# Vérification et conversion du taux de natalité
if (class(df$taux_de_natalite_annuel_moyen_2015_2021) != "numeric") {
  df$taux_de_natalite_annuel_moyen_2015_2021 <- as.numeric(as.character(df$taux_de_natalite_annuel_moyen_2015_2021))
}

# 📌 1️⃣ Histogramme du taux de mortalité
p1 <- ggplot(df, aes(x = taux_de_mortalite_annuel_moyen_2015_2021)) +
  geom_histogram(bins = 30, fill = "red", alpha = 0.7, color = "black") +
  labs( 
       x = "Taux de mortalité", 
       y = "Nombre de communes") +
  theme_minimal()

# 📌 2️⃣ Histogramme du taux de natalité
p2 <- ggplot(df, aes(x = taux_de_natalite_annuel_moyen_2015_2021)) +
  geom_histogram(bins = 30, fill = "blue", alpha = 0.7, color = "black") +
  labs(
       x = "Taux de natalité", 
       y = "Nombre de communes") +
  theme_minimal()

# 📌 3️⃣ Nuage de points pour voir la relation entre mortalité et natalité
p3 <- ggplot(df, aes(x = taux_de_mortalite_annuel_moyen_2015_2021, 
                     y = taux_de_natalite_annuel_moyen_2015_2021)) +
  geom_point(alpha = 0.7, color = "purple") +
  geom_smooth(method = "lm", color = "black", linetype = "dashed") +  # Ajout d'une tendance linéaire
  labs(
       x = "Taux de mortalité",
       y = "Taux de natalité") +
  theme_minimal()

# 📌 4️⃣ Courbes de densité pour mieux voir la distribution
p4 <- ggplot(df) +
  geom_density(aes(x = taux_de_mortalite_annuel_moyen_2015_2021, fill = "Mortalité"), alpha = 0.5, color = "red") +
  geom_density(aes(x = taux_de_natalite_annuel_moyen_2015_2021, fill = "Natalité"), alpha = 0.5, color = "blue") +
  labs(
       x = "Taux",
       y = "Densité") +
  scale_fill_manual(values = c("Mortalité" = "red", "Natalité" = "blue")) +
  theme_minimal()

# 📌 Affichage de tous les graphiques ensemble
library(gridExtra)
grid.arrange(p1, p2, p3, p4, ncol = 2)

```

```{r, fig.align='center', fig.cap= "Répartition du nombre et du taux de consultations"}
library(ggplot2)
library(patchwork)

# Premier graphique pour nb_visite
plot1 <- ggplot(data) +
  aes(x = nb_visite) +
  geom_histogram(bins = 30L, fill = "gray") +
  theme_minimal() +
  ylab("Nombre de consultations") +
  xlab("")

# Deuxième graphique pour taux_visites_19_ans_ou_plus
plot2 <- ggplot(data) +
  aes(x = taux_visites_19_ans_ou_plus) +
  geom_histogram(bins = 30L, fill = "gray") +
  theme_minimal() +
  ylab("Taux de consultations") +
  xlab("")

# Combinaison des deux graphiques
plot1 + plot2

```



### Analyse bivariée

Nous allons ici, voir s'il y a un lien à priori entre le taux de
consultation et certaines de nos variables explicatives. Ainsi, nous
avons d'abord réalisé une analyse descriptive bivariée puis nous avons
calculé la corrélation de Pearson pour évaluer le lien linéaire entre le
taux de consulation et des variables telles que la population totale, la
part des personnes agées (75 ans et plus), la part de quelques CSP
(ouvriers et retraités).

#### Taux de consultation et population totale
$\\$
```{r}
# Calcul des quantiles
quantiles <- quantile(data$population_municipale_2021_x, probs = c(1/3, 2/3), na.rm = TRUE)

# Créeation des classes avec les bornes des intervalles
data_pop <- data %>%
  mutate(taille_commune = case_when(
    population_municipale_2021_x <= quantiles[1] ~ paste0("Petite (<= ", round(quantiles[1]), ")"),
    population_municipale_2021_x <= quantiles[2] ~ paste0("Moyenne (", round(quantiles[1] + 1), " - ", round(quantiles[2]), ")"),
    TRUE ~ paste0("Grande (> ", round(quantiles[2]), ")")
  )) %>%
  group_by(taille_commune) %>%
  summarise("Taux de consulations"= mean(taux_visites, na.rm = TRUE))

# Affichage des résultats dans le RMarkdown
kable(data_pop, caption = "Taux de consultations selon la taille de la commune")
```

En divisant les communes en trois groupes égaux (ou presque égaux) en
fonction de la population totale, il ressort qu'en moyenne, plus la
taille de la commune est importante plus le taux de consulations est
élevé.

#### Taux de consultation et population âgée

```{r}
# Calcul de la médiane
mediane <- median(data$nb_de_pers_agees_de_75_ans_ou_plus_2021, na.rm = TRUE)

# Créeation des classes avec les bornes des intervalles
data_age <- data %>%
  mutate(population_agee_importante = case_when(
    nb_de_pers_agees_de_75_ans_ou_plus_2021 <= mediane ~ paste0("Non (<= ", round(mediane), ")"),
    TRUE ~ paste0("Oui (> ", round(mediane), ")")
  )) %>%
  group_by(population_agee_importante) %>%
  summarise(consultations_moyennes = mean(taux_visites, na.rm = TRUE))

# Affichage des résultats dans le RMarkdown
kable(data_age, caption = "Taux de consultations selon la population âgée")
```

```{r, fig.align='center', fig.cap="Relation entre taux de consultations et part des plus de 75 ans"}
ggplot(data = data, aes(x = part_des_pers_agees_de_75_ans_ou_2021 , y = taux_visites_19_ans_ou_plus)) +
  geom_point(color = "blue", size = 3) +          # Points bleus
  geom_smooth(method = "lm", se = TRUE, color = "red") +  # Droite de tendance (modèle linéaire)
  labs(
    x = "Part des plus de 75 ans",
    y = "Taux de consultation"
  ) +
  theme_minimal()

```

Les communes avec une population âgée importante (communes dont la
population âgée de 75 ans ou plus est supérieure à la médiane) ont en
moyenne un taux de consultations plus faible.

#### Taux de consultation et CSP
$\\$
```{r eval=FALSE, fig.align='center', fig.cap="Relations entre le taux de consultatiosn et certaines le nombre de certaines catégories socioprofessionnelle", include=FALSE}
# Chargement les bibliothèques nécessaires
library(ggplot2)
library(gridExtra)

# Standarisation des variables pour prendre en compte l'effet de la taille des variables et rendre les comparaisons plus équitables
#data_csp <- data %>%
  #mutate(across(c(taux_visites, 13:20), scale))

data_csp <- data

# Création les graphiques
plot1 <- ggplot(data_csp, aes(x = population_de_15_ans_ou_selon_la_csp_2021_agriculteurs_exploitants, y = taux_visites)) +
  geom_point() +
  labs(title = "", x = "Agriculteurs", y = "Taux de visites")

plot2 <- ggplot(data_csp, aes_string(x = names(data)[14], y = "taux_visites")) +
  geom_point() +
  labs(title = "", x = "Artisans", y = "Taux de visites")

plot3 <- ggplot(data_csp, aes_string(x = names(data)[15], y = "taux_visites")) +
  geom_point() +
  labs(title = "", x = "Cadres", y = "Taux de visites")

plot4 <- ggplot(data_csp, aes_string(x = names(data)[16], y = "taux_visites")) +
  geom_point() +
  labs(title = "", x = "Professions intermédiaires", y = "Taux de visites")

plot5 <- ggplot(data_csp, aes_string(x = names(data)[17], y = "taux_visites")) +
  geom_point() +
  labs(title = "", x = "Employés", y = "Taux de visites")

plot6 <- ggplot(data_csp, aes_string(x = names(data)[18], y = "taux_visites")) +
  geom_point() +
  labs(title = "", x = "Ouvriers", y = "Taux de visites")

plot7 <- ggplot(data_csp, aes_string(x = names(data)[19], y = "taux_visites")) +
  geom_point() +
  labs(title = "", x = "Retraités", y = "Taux de visites")

plot8 <- ggplot(data_csp, aes_string(x = names(data)[20], y = "taux_visites")) +
  geom_point() +
  labs(title = "", x = "Sans activites", y = "Taux de visites")

# Affichage des graphiques ensemble
grid.arrange(plot1, plot2, plot3, plot4, plot5, plot6, plot7, plot8, ncol = 2)
```


Aucune catégorie ne semble montrer une relation linéaire évidente avec
le taux de visite. Par ailleurs, pour toutes les catégories
socio-professionnelles, la majorité des communes se situent dans une
plage de proportions faibles, ce qui limite la variabilité observable
dans les relations. Une analyse statistique supplémentaire, comme le
calcul de corrélations, serait nécessaire pour confirmer ou infirmer les
relations observées visuellement.

#### Analyse de corrélation

$\\$

Les résultats de la corrélation de Pearson sont consignées dans le
tableau suivant :

```{r}
# Fonction de conversion
conversion_en_numeric <- function(data, columns) {
  resultat <- data %>%
    mutate(across(all_of(columns), as.numeric))
  return (resultat)
}
# Liste des variables à tester avec taux_de_consultation
variables <- c("population_municipale_2021_x", "part_des_pers_agees_de_75_ans_ou_2021", 
               "population_de_15_ans_ou_selon_la_csp_2021_retraites", "population_de_15_ans_ou_selon_la_csp_2021_ouvriers")

data <- conversion_en_numeric(data, variables)


# Initialisation du tableau pour stocker les résultats
resultats <- data.frame(Variable = character(), Correlation = numeric(), P_value = numeric())

# Calcul de la corrélation pour chaque variable et tester la significativité
for (var in variables) {
  test <- cor.test(data$taux_visites_19_ans_ou_plus, data[[var]], method = "pearson")
  resultats <- rbind(resultats, data.frame(
    Variable = var,
    Correlation = test$estimate,
    P_value = test$p.value
  ))
}

# Format du tableau avec la significativité
resultats$Significatif <- ifelse(resultats$P_value < 0.05, "Oui", "Non")

# Affichage du tableau dans le RMarkdown
kable(resultats, caption = "Corrélations de Pearson entre le taux de consultation et les autres variables")
```

Les résultats nous montrent que le taux de consultation est positivement
corrélé à la population ainsi qu'à celle de plus de 15 ans. Cependant la
corrélation est faible. Par ailleurs, la corrélation est négative avec
la part des personnes agées de plus de 75 ans. Cela dit, plus la part
des plus de 75 ans augmente moins est le taux de consultations dans une
commune. Cela peut vouloir dire que les personnes de plus de 75 ans sont
ceux qui ne se consultent pas assez.

```{r, fig.align='center', fig.cap= "Corrélations entre le nombre de visite et quelques variables"}
# Sélectionner uniquement les variables d'intérêt
# 📌 Définition des noms lisibles pour les variables
nom_variables <- c(
  "taux_de_mortalite_annuel_moyen_2015_2021" = "Mortalité",
  "taux_de_natalite_annuel_moyen_2015_2021" = "Natalité",
  "part_des_familles_sans_enf_de_de_25_ans_2021" = "Sans enfants",
  "part_des_familles_avec_1_enf_de_de_25_ans_2021" = "Un enfant",
  "part_des_familles_avec_3_enf_ou_plus_de_de_25_ans_2021" = "Trois enfants",
  "nb_visite" = "Nombre de visites"
)

# 📌 Sélectionner les variables d'analyse
variables_analyse <- names(nom_variables)

df_analyse <- df[variables_analyse]

# 📌 Convertir toutes les colonnes en numérique
df_analyse <- df_analyse %>% mutate(across(everything(), as.numeric))

# 📌 Supprimer les valeurs manquantes
df_analyse <- na.omit(df_analyse)  

# 📌 Calculer les corrélations
cor_matrix <- cor(df_analyse, use="complete.obs")

# 📌 Trier les corrélations par ordre décroissant
cor_target <- sort(cor_matrix["nb_visite", ], decreasing=TRUE)

# 📌 Remplacer les noms de variables par des noms plus lisibles
cor_data <- data.frame(
  Variable = names(cor_target),
  Correlation = cor_target
)

# 📌 Appliquer les nouveaux noms
cor_data$Variable <- nom_variables[cor_data$Variable]

# 📌 Exclure "Nombre de visites" du graphique
cor_data <- cor_data[cor_data$Variable != "Nombre de visites", ]

# 📌 Afficher le barplot des corrélations
ggplot(cor_data, aes(x = reorder(Variable, Correlation), y = Correlation, fill = Correlation)) +
  geom_bar(stat="identity") +
  coord_flip() +
  scale_fill_gradient2(low="blue", mid="white", high="red", midpoint=0) +
  labs(
       x="Variables",
       y="Coefficient de corrélation") +
  theme_minimal()

```


### Autocorrélation

L’autocorrélation spatiale est une mesure essentielle pour analyser la
dépendance entre des observations géographiques. Dans notre étude nos
données sont des données portant sur des communes. Ainsi il peut exister
une dépendance entre nos taux de consultations du fait de la proximité
des communes ou de l'appartenance à un même département ou région. Ainsi
nous allons mesurer cette dépendance en évaluant l'autocorrélation
spatiale. Dans ce contexte, **l’indice de Moran** est largement utilisé
pour quantifier cette dépendance en fournissant une mesure globale de
l’autocorrélation spatiale.

#### Définition de l’indice de Moran
$\\$
L’indice de Moran ($I$) évalue la similitude des valeurs d’une variable
entre différentes entités géographiques (par exemple, des communes) en
fonction de leur proximité spatiale. Il se base sur la matrice de poids
spatiale ($W$), qui définit les relations entre ces entités.

#### Formule de l’indice de Moran
$\\$
La formule mathématique de l’indice de Moran est la suivante :

\begin{tcolorbox}[colback=mybrown!10!white, colframe=mybrown!80!black, boxrule=0.5mm]
$$
I = \frac{n}{\sum_{i=1}^n \sum_{j=1}^n w_{ij}} \cdot \frac{\sum_{i=1}^n \sum_{j=1}^n w_{ij} (x_i - \bar{x})(x_j - \bar{x})}{\sum_{i=1}^n (x_i - \bar{x})^2}
$$
\end{tcolorbox}

Où :

-   $n$ : Nombre total d’entités spatiales (Ici, le nombre de communes).

-   $x_i, x_j$ : Valeurs observées de la variable pour les entités $i$
    et $j$ (Ici le taux de consultations)

-   $\bar{x}$ : Moyenne de la variable $x$.

-   $w_{ij}$ : Poids spatial définissant la relation entre $i$ et $j$.

La matrice de $W$ peut être constuit sur la base du voisinage entre les
deux communes ou soit de la distance entre les deux communes. Dans le
premier cas alors $w_{ij}$ $w_{ij} = 1$ si $i$ et $j$ sont voisins et
$w_{ij} = 0$ sinon. Dans le second cas $w_{ij} = d_{ij}$. Nous allons
dans notre cas utiliser une matrice de poids basée sur la distance,
notamment celle d'Haversine.

#### Matrice de poids basée sur la distance de Haversine

#### Définition de la distance de Haversine

$\\$

La distance de Haversine est une mesure de la distance entre deux points
sur une sphère, basée sur leurs coordonnées géographiques ($latitude$ et
$longitude$). Elle est particulièrement utile pour les données
géographiques projetées sur une surface sphérique, comme la Terre.


#### Formule de la distance de Haversine

$\\$

Si l'on considère deux points ($i$) et ($j$), la distance ($d_{ij}$)
entre ces deux points sur la surface d'une sphère de rayon ($r$) est
donnée par :

\begin{tcolorbox}[colback=mybrown!10!white, colframe=mybrown!80!black, boxrule=0.5mm]
$$
 d_{ij} = 2r \cdot \arcsin\left(\sqrt{\sin^2\left(\frac{\phi_j - \phi_i}{2}\right) + \cos(\phi_i)\cos(\phi_j)\sin^2\left(\frac{\lambda_j - \lambda_i}{2}\right)}\right)
$$
\end{tcolorbox}

Où : - $r$ : Rayon de la Terre (environ 6371 km).

-   $\phi_i, \phi_j$ : Latitudes des points $i$ et $j$ (en radians).

-   $\lambda_i, \lambda_j$ : Longitudes des points $i$ et $j$ (en
    radians). Après calcul nous avons ces statistiques sur nos
    distances.

```{r}
# Charger les bibliothèques nécessaires

#  (latitude, longitude)
library(spdep)     # Pour les fonctions de pondération spatiale et test de Moran
library(geosphere) # Pour les calculs de distances géodésiques

# Vérification que les colonnes latitude et longitude existent dans `data`
if (!("latitude" %in% names(data)) || !("longitude" %in% names(data))) {
  stop("Les colonnes 'latitude' et 'longitude' doivent exister dans la base de données.")
}

# Vérification des valeurs manquantes dans les coordonnées
if (anyNA(data$latitude) || anyNA(data$longitude)) {
  stop("Les colonnes 'latitude' et 'longitude' ne doivent pas contenir de valeurs manquantes.")
}

# Création de la matrice des coordonnées
coords <- data.frame(
  lat = data$latitude,
  lon = data$longitude
)

# Calcul des distances géodésiques (en mètres) avec la méthode de Vincenty
dist_matrix <- distm(coords, fun = distVincentySphere)/1000

# Gérer les distances nulles ou infinies
if (any(diag(dist_matrix) != 0)) {
  diag(dist_matrix) <- 0  # Auto-distance définie comme 0
}
if (any(is.infinite(dist_matrix))) {
  stop("La matrice des distances contient des valeurs infinies, vérifiez les coordonnées.")
}

# Résumé statistique de toutes les distances
distance_values <- as.vector(dist_matrix)
#summary(distance_values)
```

Une visualtion de la densité de nos distance nous donne ceci, indiquant une forte asymétrie à gauche de la distribution. En d'autres termes,les communes étudiées sont assez rapprochées les unes des autres pour la plupart. 

```{r fig.align='center', fig.cap="Densité des distances"}
dist_df <- data.frame(Distance = as.vector(dist_matrix))
# Tracer la densité
ggplot(dist_df, aes(x = Distance)) +
  geom_density(fill = "blue", alpha = 0.4) +
  theme_minimal() +
  labs(x = "Distance", y = "Densité")

```

#### Construction de la matrice de poids

\
Pour construire la matrice de poids, nous avons alors suivi ces étapes.
\

1.  Calculer les distances de Haversine entre chaque paire d’entités.
2.  Définir un seuil de distance maximale ($d_{max}$) :
    -   Si $d_{ij} < d_{max}$, $w_{ij} = \frac{1}{d_{ij}}$.
    -   Sinon, $w_{ij} = 0$.
3.  Normaliser les poids pour que chaque ligne de la matrice ait une
    somme égale à 1 : $$
     w_{ij}^{norm} = \frac{w_{ij}}{\sum_{j} w_{ij}}.
    $$

```{r}
# Créer la matrice de poids (inverse des distances)
weight_matrix <- 1 / dist_matrix
diag(weight_matrix) <- 0  # Aucun poids pour soi-même

# Gérer les cas où les distances sont nulles ou infinies
weight_matrix[is.infinite(weight_matrix)] <- 0

# Créer l'objet spatial de pondération
W <- mat2listw(weight_matrix, style = "W")

# Vérifier que la variable à analyser existe et ne contient pas de NA
if (!("taux_visites_19_ans_ou_plus" %in% names(data))) {
  stop("La colonne 'taux_visites_19_ans_ou_plus' doit exister dans la base de données.")
}
values <- data$taux_visites_19_ans_ou_plus

if (anyNA(values)) {
  stop("La colonne 'taux_visites_19_ans_ou_plus' ne doit pas contenir de valeurs manquantes.")
}

# Calcul de l'indice de Moran
moran_result <- moran.test(values, W, zero.policy = TRUE)

# Afficher les résultats
kable(moran_result[["estimate"]], caption = "Résultats du test de Moran")

```

Ainsi dans notre étude, nous avons trouvé un indice de Moran égale à
`r moran_result[["estimate"]][["Moran I statistic"]]`. Le test nous a
permi d'obtenir une p-value de `r moran_result[["p.value"]]`. Ce qui
permet de conclure qu'il y a effectivement une autocorrélation positive
et significative entre les communes selon leur taux de consultations.


# Discussion

# Conclusion

# Références bibliographiques


# Annexes

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{../cartes/nombre_de_consulatations}
    \caption{Carte du nombre de consultations par commune}
    \label{fig:figure}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{../cartes/taux_de_consultations}
    \caption{Carte du taux de consultations par commune}
    \label{fig:figure}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{../cartes/taux_de_consultations_plus_19_ans}
    \caption{Carte du taux de consultations par commune pour les plus de 19 ans}
    \label{fig:figure}
\end{figure}
