# Chargement des packages

library(stringi)
library(dplyr)
library(tidyverse)
library(summarytools)
library(gridExtra)
library(purrr)
library(skimr)

# Importation des donn√©es de d√©monstration

demo <- read.csv("data/demof2.csv", sep = ";", dec=",")
data <- read.csv("data/data.csv", sep = ",", dec=",")
View(demo)
str(demo)
names(demo)[names(demo) == "Libell√©"] <- "libelle_maj"
data = demo
## Fonction prenant en entr√©e un base et nettoie les noms des colonnes

nettoyer_noms_colonnes <- function(data){
  names(data) <- names(data) %>%
    stri_trans_general("Latin-ASCII") %>% # Suppression des accents
    gsub("\\s+", "_", .) %>% # Remplacement des espaces par des underscores
    gsub("\\.+", "_", .) %>% # Remplacement des points par des underscores
    tolower() # Conversion en minuscules
  return (data) 
}

## Nettoyage des colonnes de la base demo
demo <- nettoyer_noms_colonnes(demo)
names(demo)


# Fusion des bases et cr√©ation des varaiables

## Importation de la base generalise
generalise <- read.csv("data/generalise.csv", sep=";")
str(generalise)

## Importation de la base pour les lon et lat manquantes
donnees_manquantes <- read.csv(
  "data/communes_manquantes_latitudes_longitudes.csv", sep=";", dec=".")
str(donnees_manquantes)

donnees_manquantes$longitude <- donnees_manquantes$longitude %>%
  str_replace_all(",", "") %>%  # Supprime les virgules
  as.numeric()

## Nettoyage dans les noms des colonnes
generalise <- nettoyer_noms_colonnes(generalise)
donnees_manquantes <- nettoyer_noms_colonnes(donnees_manquantes)

## Fusion des bases
data <- demo %>% 
  inner_join(generalise, by ="code") %>%
  left_join(donnees_manquantes, by = "code") %>%
  mutate(
    longitude = ifelse(is.na(longitude.x), longitude.y, longitude.x),
    latitude = ifelse(is.na(latitude.x), latitude.y, latitude.x)
  ) %>%
  select(-longitude.x, -longitude.y, -latitude.x, -latitude.y)


nrow(demo)
nrow(generalise)
nrow(data)

## Filtrons les communes n'appartenant pas au d√©partement 97
data <- data %>% filter(departement != 97)



## Cr√©ation de la variable taux de visites
data <- data %>% 
  mutate(taux_visites = nb_visite/population_municipale_2021_x)

## Cr√©ation de la variabe taux de visites pour les plus de 19 ans
data <- data %>%
  mutate(pop_19_ans_ou_plus = pop_15_ans_ou_plus - pop_15_19_ans,
       taux_visites_19_ans_ou_plus = nb_visite / pop_19_ans_ou_plus)

summary(data$taux_visites)
summary(data$taux_visites_19_ans_ou_plus)

skim(data)

## Exportation de la base finale 
write.csv(data, "data/data.csv", row.names = FALSE)

## Statistiques descriptives sur le nombre de visite

summary(data$nb_visite)

ggplot(data) +
  aes(x = nb_visite) +
  geom_histogram(bins = 30L, fill = "gray") +
  theme_minimal() +
  ggtitle(label = "Distribution du nombre de visites par commune") +
  ylab("") +
  xlab("")


# Charger les biblioth√®ques n√©cessaires
library(ggplot2)
library(FactoMineR)
library(factoextra)
library(corrplot)
library(dplyr)

# Charger les donn√©es (remplace "Test.csv" par ton vrai fichier)
df <- read.csv("data/data.csv", sep = ",", dec=",")

# V√©rifier la structure des donn√©es
str(df)

# Conversion des colonnes en num√©rique si n√©cessaire
df_numeric <- df %>%
  select(where(is.numeric)) %>%  # S√©lectionne les colonnes num√©riques
  select(-nb_visite)             # Exclut la variable cible

# Standardiser les donn√©es pour l'ACP
df_scaled <- scale(df_numeric)

# Effectuer l'ACP
pca_result <- PCA(df_scaled, scale.unit=TRUE, graph=FALSE)

# Afficher le pourcentage de variance expliqu√©e
fviz_eig(pca_result, addlabels=TRUE, ylim=c(0,100))

# Afficher la contribution des variables aux deux premi√®res composantes principales
fviz_pca_var(pca_result, col.var="contrib", gradient.cols=c("blue", "red"), repel=TRUE)

# -------------------------------------------------
# üìå ANALYSE BIVARI√âE : Corr√©lation avec nb_visite
# -------------------------------------------------
# Ajouter la variable cible
df_numeric$nb_visite <- df$nb_visite

# Calculer les corr√©lations
cor_matrix <- cor(df_numeric, use="complete.obs")

# Trier les variables les plus corr√©l√©es avec nb_visite
cor_target <- sort(cor_matrix["nb_visite",], decreasing=TRUE)

# Afficher les 10 variables les plus corr√©l√©es avec nb_visite
print(cor_target[1:30])

# Visualisation des corr√©lations sous forme de heatmap
corrplot(cor_matrix, method="color", type="upper", tl.col="black", tl.srt=45)


# Charger les biblioth√®ques n√©cessaires
library(ggplot2)
library(dplyr)
library(tidyr)

colnames(df) <- gsub("homme_", "hommes_", colnames(df))
colnames(df) <- gsub("hommes_70_47$", "hommes_70_74", colnames(df))


# Charger les donn√©es (remplace "Test.csv" par ton fichier)
df <- read.csv("Test.csv", sep="\t", header=TRUE)

# S√©lectionner les colonnes de la pyramide des √¢ges
age_groups <- c("0_4", "5_9", "10_14", "15_19", "20_24", "25_29", "30_34", "35_39",
                "40_44", "45_49", "50_54", "55_59", "60_64", "65_69", "70_74",
                "75_79", "80_84", "85_89", "90_94", "95_plus")

# Restructurer les donn√©es pour la visualisation
hommes_vars <- intersect(colnames(df), paste0("hommes_", age_groups))
femmes_vars <- intersect(colnames(df), paste0("femmes_", age_groups))

# Cr√©er la pyramide des √¢ges avec les hommes d'abord, puis les femmes
pyramide <- data.frame(
  Age = rep(age_groups, 2),  # Liste tous les √¢ges d'abord pour les hommes, puis pour les femmes
  Sexe = c(rep("Homme", length(age_groups)), rep("Femme", length(age_groups))),
  Population = c(colSums(df[paste0("hommes_", age_groups)], na.rm=TRUE),
                 -colSums(df[paste0("femmes_", age_groups)], na.rm=TRUE))  # Femmes en n√©gatif
)



ggplot(pyramide, aes(x=Age, y=Population, fill=Sexe)) +
  geom_bar(stat="identity", width=0.8) +
  coord_flip() +  # Pour afficher en pyramide
  scale_y_continuous(labels = abs) +  # Afficher les valeurs absolues
  labs(title="Pyramide des √¢ges",
       x="Tranche d'√¢ge",
       y="Population",
       fill="Sexe") +
  theme_minimal() +
  scale_fill_manual(values=c("blue", "pink"))  # Couleurs pour Homme/Femme


## D'autres analyses

# Charger les biblioth√®ques n√©cessaires
library(ggplot2)
library(dplyr)
library(corrplot)

# S√©lectionner uniquement les variables d'int√©r√™t
variables_analyse <- c("taux_de_mortalite_annuel_moyen_2015_2021", 
                       "taux_de_natalite_annuel_moyen_2015_2021", 
                       "part_des_familles_sans_enf_de_de_25_ans_2021", 
                       "part_des_familles_avec_1_enf_de_de_25_ans_2021", 
                       "part_des_familles_avec_3_enf_ou_plus_de_de_25_ans_2021", 
                       "nb_visite")

df_analyse <- df[variables_analyse]
# Convertir toutes les colonnes en num√©rique
df_analyse <- df_analyse %>% mutate(across(everything(), as.numeric))

# V√©rifier les valeurs manquantes et les g√©rer si besoin
df_analyse <- na.omit(df_analyse)  

# Calculer les corr√©lations entre nb_visite et les autres variables
cor_matrix <- cor(df_analyse, use="complete.obs")

# Trier les corr√©lations par ordre d√©croissant
cor_target <- sort(cor_matrix["nb_visite",], decreasing=TRUE)

# Afficher le top des corr√©lations
print(cor_target)

# Visualiser les corr√©lations sous forme de barplot
ggplot(data = data.frame(Variable = names(cor_target), Correlation = cor_target), 
       aes(x = reorder(Variable, Correlation), y = Correlation, fill = Correlation)) +
  geom_bar(stat="identity") +
  coord_flip() +
  scale_fill_gradient2(low="blue", mid="white", high="red", midpoint=0) +
  labs(title="Corr√©lations entre le nombre de visite et les autres variables",
       x="Variables",
       y="Coefficient de corr√©lation") +
  theme_minimal()


################################################
### MORTALITE ET NATALITE########################"

# Charger les biblioth√®ques n√©cessaires
library(ggplot2)
library(gridExtra)  # Pour afficher plusieurs graphiques ensemble

# üìå 1Ô∏è‚É£ Histogramme du taux de mortalit√©
p1 <- ggplot(df, aes(x = taux_de_mortalite_annuel_moyen_2015_2021)) +
  geom_histogram(bins = 30, fill = "red", alpha = 0.7, color = "black") +
  labs(title = "Distribution du taux de mortalit√© (2015-2021)", 
       x = "Taux de mortalit√© moyen", 
       y = "Nombre de communes") +
  theme_minimal()

# üìå 2Ô∏è‚É£ Histogramme du taux de natalit√©
p2 <- ggplot(df, aes(x = taux_de_natalite_annuel_moyen_2015_2021)) +
  geom_histogram(bins = 30, fill = "blue", alpha = 0.7, color = "black") +
  labs(title = "Distribution du taux de natalit√© (2015-2021)", 
       x = "Taux de natalit√© moyen", 
       y = "Nombre de communes") +
  theme_minimal()

# üìå 3Ô∏è‚É£ Nuage de points pour voir la relation entre mortalit√© et natalit√©
p3 <- ggplot(df, aes(x = taux_de_mortalite_annuel_moyen_2015_2021, 
                     y = taux_de_natalite_annuel_moyen_2015_2021)) +
  geom_point(alpha = 0.7, color = "purple") +
  geom_smooth(method = "lm", color = "black", linetype = "dashed") +  # Ajout d'une tendance lin√©aire
  labs(title = "Relation entre taux de mortalit√© et taux de natalit√©",
       x = "Taux de mortalit√© moyen (2015-2021)",
       y = "Taux de natalit√© moyen (2015-2021)") +
  theme_minimal()

# üìå 4Ô∏è‚É£ Courbes de densit√© pour mieux voir la distribution
p4 <- ggplot(df) +
  geom_density(aes(x = taux_de_mortalite_annuel_moyen_2015_2021, fill = "Mortalit√©"), alpha = 0.5, color = "red") +
  geom_density(aes(x = taux_de_natalite_annuel_moyen_2015_2021, fill = "Natalit√©"), alpha = 0.5, color = "blue") +
  labs(title = "Distribution des taux de mortalit√© et natalit√©", 
       x = "Taux",
       y = "Densit√©") +
  scale_fill_manual(values = c("Mortalit√©" = "red", "Natalit√©" = "blue")) +
  theme_minimal()

# Afficher tous les graphiques ensemble
grid.arrange(p1, p2, p3, p4, ncol = 2)

